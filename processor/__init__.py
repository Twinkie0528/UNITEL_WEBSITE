# ======================================================
# processor/__init__.py ‚Äî Unified Chat Processor (Context-Aware)
# (–ó–∞—Å–≤–∞—Ä–ª–∞—Å–∞–Ω, TF-–∏–π–Ω “Ø–ª–¥—ç–≥–¥—ç–ª–≥“Ø–π —Ö—É–≤–∏–ª–±–∞—Ä)
# ======================================================

from __future__ import annotations
import os, json, random, pickle, re, numpy as np
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any

# --- –ù—ç–≥—Ç–≥—ç—Å—ç–Ω Imports ---
from .file_handler import extract_text_from_file, extract_records_from_file
from .prompt_builder import (
    build_prompt, 
    build_general_prompt,
    build_sentiment_prompt, # (–®–∏–Ω—ç —Ö—É–≤–∏–ª–±–∞—Ä–∞–∞—Å)
    # detect_intent,        # (‚ùó –ó–êC–í–ê–†: TF-–∏–π–Ω “Ø–ª–¥—ç–≥–¥—ç–ª —É—Å—Ç–≥–∞–≥–¥—Å–∞–Ω)
    has_textual_field,      # (–•—É—É—á–∏–Ω —Ö—É–≤–∏–ª–±–∞—Ä–∞–∞—Å)
    safe_json               # (–•—É—É—á–∏–Ω —Ö—É–≤–∏–ª–±–∞—Ä–∞–∞—Å)
)
from .llm_client import ask_llm
# --- ”®”®–†–ß–õ”®–ì–î–°”®–ù IMPORT ---
from .sentiment_analyzer import analyze_sentiment, analyze_sentiment_ai
from .data_connector import fetch_graph_data
# GPT intent engine (—à–∏–Ω—ç)
from .intent_classifier import classify_intent, get_intent_response

# -------- CONTEXT MEMORY (2.1) -----------
# (–®–∏–Ω—ç —Ö—É–≤–∏–ª–±–∞—Ä–∞–∞—Å)
USER_CONTEXTS = {}

def get_user_context(session_id: str):
    """–°–µ—à–Ω –±“Ø—Ä–∏–π–Ω —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω context (history, last_file) —Ö–∞–¥–≥–∞–ª–∞—Ö."""
    return USER_CONTEXTS.get(session_id, {"history": [], "last_file": None})

def update_user_context(session_id: str, message: str, file_meta: str = None):
    ctx = USER_CONTEXTS.setdefault(session_id, {"history": [], "last_file": None})
    ctx["history"].append(message) 
    if file_meta:
        ctx["last_file"] = file_meta
    ctx["history"] = ctx["history"][-20:]

# (–•—É—É—á–∏–Ω TensorFlow-–∏–π–Ω setup –±–æ–ª–æ–Ω utility —Ñ—É–Ω–∫—Ü—É—É–¥ —ç–Ω–¥ –±–∞–π—Ö–≥“Ø–π)

# ======================================================
# MAIN CHAT PROCESSOR (–ù–≠–ì–¢–ì–≠–°–≠–ù)
# ======================================================
def process_query(msg: str,
                  session_id: str, # <--- (–®–∏–Ω—ç)
                  files: Optional[List[str]] = None,
                  user: Optional[str] = None) -> str:
    """
    Unified logic for Chatbot: (Context-Aware)
    """
    msg = (msg or "").strip()
    if not msg:
        return "‚ö†Ô∏è –•–æ–æ—Å–æ–Ω –∞—Å—É—É–ª—Ç –±–∞–π–Ω–∞."

    # --- (2.2a) Context –∞–≤–∞—Ö (–®–∏–Ω—ç —Ö—É–≤–∏–ª–±–∞—Ä–∞–∞—Å) ---
    context = get_user_context(session_id)
    history = context.get("history", [])
    last_file_meta = context.get("last_file")
    # ---------------------------

    files = files or []
    lower = msg.lower()

    # ---------- 1Ô∏è‚É£ FILE ATTACHED (2.2b) ----------
    if files:
        all_records: list[dict] = []
        blobs: list[tuple[str, str]] = []
        file_meta = "Uploaded File"

        # (–•—É—É—á–∏–Ω –∫–æ–¥—ã–Ω –ª–æ–≥–∏–∫: record/blob —è–ª–≥–∞—Ö)
        for f in files:
            try:
                recs, meta1 = extract_records_from_file(f)
                if recs:
                    all_records.extend(recs)
                    file_meta = meta1
                else:
                    text, meta2 = extract_text_from_file(f)
                    blobs.append((text, meta2))
                    file_meta = meta2
            except Exception as e:
                blobs.append((f"[extract_error:{e}]", f"[{Path(f).name}]"))

        # (–•—É—É—á–∏–Ω –∫–æ–¥—ã–Ω –ª–æ–≥–∏–∫: sentiment —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö)
        wants_sentiment = any(k in lower for k in [
            "sentiment","—Å—ç—Ç–≥—ç–≥–¥—ç–ª","feedback","comment","tone","—ç–µ—Ä—ç–≥","—Å”©—Ä”©–≥"
        ])

        # (–•—É—É—á–∏–Ω –∫–æ–¥—ã–Ω –ª–æ–≥–∏–∫: –•“Ø—Å–Ω—ç–≥—Ç—ç–Ω ”©–≥”©–≥–¥”©–ª –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö)
        if all_records:
            # ‚ùó –ó–êC–í–ê–†: intent_guess = detect_intent(...) –º”©—Ä–∏–π–≥ —É—Å—Ç–≥–∞—Å–∞–Ω (TF-–∏–π–Ω “Ø–ª–¥—ç–≥–¥—ç–ª)
            textish = has_textual_field(all_records)

            # --- –°–≠–¢–ì–≠–ì–î–≠–õ–¢–≠–ô –§–ê–ô–õ: (AI / –õ–û–ö–ê–õ) ---
            if wants_sentiment and textish:
                # === AI –±—É—é—É LLM-–¥ —Å—É—É—Ä–∏–ª—Å–∞–Ω —Ö—É–≤–∏–ª–±–∞—Ä ===
                USE_AI_SENTIMENT = True   # <== toggle: True –±–æ–ª AI –∞—à–∏–≥–ª–∞–Ω–∞, False –±–æ–ª —Ö—É—É—á–∏–Ω Lexicon

                if USE_AI_SENTIMENT:
                    answer = analyze_sentiment_ai(all_records, meta=file_meta)
                    update_user_context(session_id, msg, file_meta=file_meta)
                    return answer
                else:
                    # (–•—É—É—á–∏–Ω –ª–æ–∫–∞–ª sentiment-–∏–π–Ω –ª–æ–≥–∏–∫)
                    s = analyze_sentiment(all_records)
                    payload = { "meta": file_meta, "counts": s["counts"], "ratios": s["ratios"], "examples": s["examples"] }
                    prompt = (
                        "–î–æ–æ—Ä—Ö –Ω—å —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –°–≠–¢–ì–≠–ì–î–õ–ò–ô–ù –±–æ–¥–∏—Ç —Ç–æ–æ—Ü–æ–æ (–ª–æ–∫–∞–ª) —é–º. "
                        "–¢–æ–æ–Ω—É—É–¥—ã–≥ ”©”©—Ä—á–ª”©—Ö–≥“Ø–π. Markdown —Ç–∞–π–ª–∞–Ω –±–∏—á–∏–∂, —Ö—É–≤—å, –¥“Ø–≥–Ω—ç–ª—Ç, 3‚Äì5 –≥–æ–ª —Å—ç–¥—ç–≤, "
                        "—Ç”©–ª”©”©–ª”©—Ö –∏—à–ª—ç–ª“Ø“Ø–¥–∏–π–≥ –æ—Ä—É—É–ª. –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä –±–∏—á.\n\n"
                        + safe_json(payload)
                    )
                    answer = ask_llm(prompt, history=history)
                    update_user_context(session_id, msg, file_meta=file_meta)
                    return answer
            
            # ‚ùó –ó–êC–í–ê–†: Problem 4 - 'intent_guess'-–¥ —Å—É—É—Ä–∏–ª—Å–∞–Ω 'if' –Ω”©—Ö—Ü–ª–∏–π–≥ 'else' –±–æ–ª–≥–æ–∂ ”©”©—Ä—á–∏–ª—Å”©–Ω
            else:
                # --- STRUCTURED –±—É—é—É —Ç–æ–æ–Ω ”©–≥”©–≥–¥”©–ª (–°—ç—Ç–≥—ç–≥–¥—ç–ª –±–∏—à “Ø–µ–¥) ---
                # –≠–Ω—ç –±–æ–ª —Å—ç—Ç–≥—ç–≥–¥—ç–ª –±–∏—à, —ç—Å–≤—ç–ª —Å—ç—Ç–≥—ç–≥–¥—ç–ª —á —Ç–µ–∫—Å—Ç—ç–Ω —Ç–∞–ª–±–∞—Ä –±–∞–π—Ö–≥“Ø–π
                # —Ç–æ—Ö–∏–æ–ª–¥–æ–ª–¥ –∞–∂–∏–ª–ª–∞—Ö –µ—Ä–¥–∏–π–Ω structured data-–Ω –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞–ª—Ç.
                prompt = build_prompt(msg, all_records, meta=file_meta)
                answer = ask_llm(prompt, history=history)
                update_user_context(session_id, msg, file_meta=file_meta)
                return answer

        # --- –¢–∞–±–ª–∏—Ü –±–∏—à / —Ç–µ–∫—Å—Ç—ç–Ω —Ñ–∞–π–ª ---
        if blobs:
            prompt = build_prompt(msg, [ {"blob": t, "meta": m} for (t,m) in blobs ], meta=file_meta)
            answer = ask_llm(prompt, history=history)
            update_user_context(session_id, msg, file_meta=file_meta)
            return answer

        # --- Fallback (–§–∞–π–ª –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∂ —á–∞–¥–∞–∞–≥“Ø–π) ---
        prompt = build_general_prompt(msg, f"[{file_meta}] structured/–±—É—Å –º–∞—Ç–µ—Ä–∏–∞–ª —Ç–∞–Ω–∏–≥–¥—Å–∞–Ω–≥“Ø–π.")
        answer = ask_llm(prompt, history=history)
        update_user_context(session_id, msg, file_meta=file_meta)
        return answer

    # ---------- 2Ô∏è‚É£ FACEBOOK / INSIGHT QUERIES ----------
    fb_keywords = ["facebook", "insight", "impression", "reach", "spend", "campaign", "ad", "graph"]
    comment_keywords = ["facebook comment", "fb comment", "–∫–æ–º–º–µ–Ω—Ç —Ç–∞—Ç", "comment —Ç–∞—Ç", "–∫–æ–º–º–µ–Ω—Ç ”©–≥"]

    if any(k in lower for k in fb_keywords + comment_keywords):
        try:
            result = fetch_graph_data(msg)
            if not result:
                return "‚ö†Ô∏è Graph API-–∞–∞—Å ”©–≥”©–≥–¥”©–ª –±—É—Ü–∞–∞–≥–¥—Å–∞–Ω–≥“Ø–π."

            links = []
            if result.get("xlsx_url"):
                links.append(f'üìò <a href="{result["xlsx_url"]}" download target="_blank">XLSX —Ç–∞—Ç–∞—Ö</a>')
            if result.get("json_url"):
                links.append(f'üßæ <a href="{result["json_url"]}" download target="_blank">JSON —Ç–∞—Ç–∞—Ö</a>')
            links_html = "<br>".join(links)

            if "comment" in lower:
                resp = f"‚úÖ {result.get('count', 0)} –∫–æ–º–º–µ–Ω—Ç —Ç–∞—Ç–ª–∞–∞.<br>{links_html}"
            elif "ad" in lower or "insight" in lower:
                resp = f"üìä Ads —Ç–∞–π–ª–∞–Ω –≥–∞—Ä–≥–∞–ª–∞–∞ ({result.get('count', 0)} –º”©—Ä).<br>{links_html}"
            else:
                resp = f"‚úÖ {result.get('count', 0)} –±–∏—á–ª—ç–≥ —Ç–∞—Ç–ª–∞–∞.<br>{links_html}"
            
            return resp

        except Exception as e:
            return f"‚ö†Ô∏è Facebook Graph API –¥–∞—Ç–∞ —Ç–∞—Ç–∞—Ö–∞–¥ –∞–ª–¥–∞–∞: {e}"

    # ‚ùó –ó–êC–í–ê–†: Problem 2 - –≠–Ω–¥ –±–∞–π—Å–∞–Ω '# 3 SENTIMENT DIRECT' –±–ª–æ–∫—ã–≥ —É—Å—Ç–≥–∞—Å–∞–Ω.
    # (–£—á–∏—Ä –Ω—å 'analyze_sentiment' –∑”©–≤—Ö”©–Ω —Ñ–∞–π–ª –¥—ç—ç—Ä –∞–∂–∏–ª–ª–∞—Ö —ë—Å—Ç–æ–π)

    # ---------- 3Ô∏è‚É£ GPT INTENT (–•—É—É—á–∏–Ω 4-—Ä –±–ª–æ–∫) ----------
    tag = classify_intent(msg)
    if tag and tag != "none":
        ans = get_intent_response(tag)
        if ans:
            update_user_context(session_id, msg, file_meta=last_file_meta)
            return ans

    # ---------- 4Ô∏è‚É£ FALLBACK ‚Üí LLM (–•—É—É—á–∏–Ω 5-—Ä –±–ª–æ–∫) ----------
    # (2.2c) –§–∞–π–ª–≥“Ø–π “Ø–µ–¥ last_file_meta-–≥ –∞—à–∏–≥–ª–∞—Ö
    blobs = []
    if last_file_meta:
        blobs.append((f"[–¢–∞–π–ª–±–∞—Ä: –•—ç—Ä—ç–≥–ª—ç–≥—á ”©–º–Ω”© –Ω—å –∞—à–∏–≥–ª–∞—Å–∞–Ω '{last_file_meta}' —Ñ–∞–π–ª—ã–Ω —Ç–∞–ª–∞–∞—Ä –∞—Å—É—É–∂ –±–∞–π–Ω–∞]", last_file_meta))

    base_prompt = build_general_prompt(msg, blobs)

    # (2.2c) History-–≥ –∞—à–∏–≥–ª–∞—Ö (‚ùó –ó–êC–í–ê–†: Problem 3 - 'history'-–≥ –∑”©–≤—Ö”©–Ω prompt-–¥ –Ω—ç–≥—Ç–≥—ç—Å—ç–Ω)
    if history:
        ctx = "\n".join(history[-8:]) 
        final_prompt = f"”®–º–Ω”©—Ö —è—Ä–∏–∞–Ω—ã —Ç–æ–≤—á —Ç“Ø“Ø—Ö:\n{ctx}\n\n–®–∏–Ω—ç –∞—Å—É—É–ª—Ç:\n{base_prompt}"
    else:
        final_prompt = base_prompt

    # 'history'-–≥ prompt-–¥ –æ—Ä—É—É–ª—Å–∞–Ω —Ç—É–ª 'ask_llm'-–¥ 'history' –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–π–≥ –¥–∞–º–∂—É—É–ª–∞—Ö–≥“Ø–π
    answer = ask_llm(final_prompt) 

    # --- (2.2c) Context —à–∏–Ω—ç—á–ª—ç—Ö ---
    update_user_context(session_id, msg, file_meta=last_file_meta) 
    
    return answer